# MOPS 財務報表爬蟲

自動化爬取公開資訊觀測站 (MOPS) 的財務報表資料,解決動態載入和反爬蟲機制問題。

## 功能特色

- 使用 Selenium 模擬真實瀏覽器操作
- 自動處理反爬蟲機制
- 從 sessionStorage 讀取動態生成的查詢結果 URL
- 自動解析表格資料並匯出為 CSV
- 支援多種市場別查詢

## 安裝步驟

### 1. 安裝 Python 套件

```bash
pip install -r requirements.txt
```

### 2. 安裝 Chrome WebDriver

系統會自動下載對應的 ChromeDriver,但需要先安裝 Google Chrome 瀏覽器。

或使用 webdriver-manager 自動管理:

```bash
pip install webdriver-manager
```

然後在程式中修改:

```python
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install())
self.driver = webdriver.Chrome(service=service, options=chrome_options)
```

## 使用方式

### 基本使用

```python
from mops_scraper import MOPSScraper

# 建立爬蟲實例
scraper = MOPSScraper(headless=False)  # headless=True 為背景執行

try:
    # 爬取資料
    result_url = scraper.scrape_data(
        market_type="sii",  # 市場別
        year=113,           # 民國年度
        season=3            # 季別
    )

    if result_url:
        # 解析表格資料
        tables = scraper.parse_table_data()

        # 儲存為 CSV
        scraper.save_to_csv(tables, "mops_financial_data.csv")

finally:
    scraper.close()
```

### 參數說明

**market_type** (市場別):
- `"sii"` - 上市
- `"otc"` - 上櫃
- `"rotc"` - 興櫃
- `"pub"` - 公開發行

**year**: 民國年度 (例如: 113)

**season**: 季別 (1, 2, 3, 4)

### 執行範例

直接執行主程式:

```bash
python mops_scraper.py
```

## 工作原理

1. **開啟網頁**: 使用 Selenium 開啟 MOPS 查詢頁面
2. **選擇條件**: 自動選擇市場別、年度、季別
3. **點擊查詢**: 模擬點擊查詢按鈕
4. **讀取 URL**: 從 sessionStorage 的 `queryResultsSet` 鍵值中取得動態生成的結果 URL
5. **開啟結果頁**: 導向至結果 URL
6. **解析資料**: 使用 pandas 解析 HTML 表格
7. **儲存資料**: 匯出為 CSV 檔案

## 核心技術

### 反爬蟲處理

```python
# 隱藏 webdriver 特徵
chrome_options.add_argument('--disable-blink-features=AutomationControlled')
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])

# 修改 navigator.webdriver 屬性
self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
    'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'
})
```

### SessionStorage 讀取

```python
query_results = self.driver.execute_script(
    "return sessionStorage.getItem('queryResultsSet');"
)
result_data = json.loads(query_results)
url = result_data['result']['url']
```

## 批次查詢範例

```python
from mops_scraper import MOPSScraper

scraper = MOPSScraper(headless=True)

# 查詢多個季度
markets = ["sii", "otc"]
years = [112, 113]
seasons = [1, 2, 3, 4]

try:
    for market in markets:
        for year in years:
            for season in seasons:
                print(f"\n處理: {market} - {year}年 Q{season}")

                result_url = scraper.scrape_data(market, year, season)

                if result_url:
                    tables = scraper.parse_table_data()
                    filename = f"mops_{market}_{year}_Q{season}.csv"
                    scraper.save_to_csv(tables, filename)

                time.sleep(5)  # 避免請求過於頻繁

finally:
    scraper.close()
```

## 注意事項

1. **執行速度**: 為避免觸發反爬蟲機制,建議在請求間加入適當延遲
2. **Chrome 版本**: 確保 Chrome 瀏覽器為最新版本
3. **網路連線**: 需要穩定的網路連線
4. **資料格式**: 不同頁面的表格結構可能不同,需視情況調整解析邏輯
5. **合法使用**: 請遵守網站的使用條款,不要過度頻繁查詢

## 故障排除

### Chrome WebDriver 版本問題

如果遇到版本不符問題,使用 webdriver-manager:

```bash
pip install webdriver-manager
```

### 元素找不到

如果無法找到查詢按鈕,可能需要更新選擇器:

```python
# 檢查網頁元素的 ID 或 class
query_button = driver.find_element(By.ID, "實際的按鈕ID")
```

### SessionStorage 為空

確保在點擊查詢後有足夠的等待時間:

```python
time.sleep(3)  # 增加等待時間
```

## 授權

本專案僅供學習研究使用,請遵守相關法律規範和網站使用條款。

虛擬環境已建立完成

  目前專案結構

  1206_mops/
  ├── venv/              # Python 虛擬環境
  ├── mops_scraper.py    # 主要爬蟲程式
  ├── requirements.txt   # 套件相依性
  ├── README.md          # 使用說明
  ├── run.sh            # 快速啟動腳本
  └── .gitignore        # Git 忽略檔案

  使用方式

  方法 1: 使用快速啟動腳本 (推薦)

  ./run.sh

  方法 2: 手動啟動虛擬環境

  # 1. 啟動虛擬環境
  source venv/bin/activate

  # 2. 執行程式
  python mops_scraper.py

  # 3. 執行完畢後,退出虛擬環境
  deactivate

  虛擬環境的優點

  1. 隔離套件: 不會影響系統的 Python 環境
  2. 版本管理: 每個專案可以有自己的套件版本
  3. 乾淨環境: 避免套件衝突
  4. 易於部署: 其他人可以用 requirements.txt 重建相同環境

  已安裝的套件

  所有相依套件都已安裝在虛擬環境中:
  - selenium 4.38.0
  - pandas 2.3.3
  - lxml 6.0.2
  - openpyxl 3.1.5
  - webdriver-manager 4.0.2

  接下來的步驟

  1. 確認有安裝 Chrome 瀏覽器
  2. 執行程式: ./run.sh 或 source venv/bin/activate && python mops_scraper.py
  3. 第一次執行會自動下載 ChromeDriver


  