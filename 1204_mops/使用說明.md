# MOPS 資產負債表爬蟲系統 - 使用說明

## 系統簡介

這是一個專業級的 MOPS（公開資訊觀測站）資產負債表爬蟲系統，專為金融公司爬取歷史資料設計。

### 核心特色

✅ **高效能並發爬取** - 使用 asyncio + aiohttp 非同步架構
✅ **自動化流程** - 從 MongoDB 讀取公司清單，自動爬取並儲存
✅ **智慧重試機制** - 自動處理網路錯誤和暫時性失敗
✅ **資料完整性** - Upsert 機制避免重複，索引確保資料一致性
✅ **完整日誌** - 詳細記錄執行過程，方便監控和除錯

## 快速開始（3 步驟）

### 1. 安裝環境

```bash
# 安裝 Python 套件
pip install -r requirements.txt

# 設定環境變數
cp .env.example .env
# 編輯 .env 設定 MongoDB 連接資訊（通常不需要修改）
```

### 2. 測試連接

```bash
# 測試 MongoDB 連接
python test_connection.py

# 測試爬蟲功能（爬取台積電的資料）
python test_scraper.py
```

### 3. 執行完整爬蟲

```bash
# 開始爬取所有公司的資料
python main.py
```

## 系統需求

### 必要條件

- Python 3.8 或更高版本
- MongoDB 4.0 或更高版本
- 穩定的網路連接

### MongoDB 資料準備

在 MongoDB 的 `TW_Stock` 資料庫中，必須有 `公司基本資料` collection，格式如下：

```javascript
{
  "stock_code": "2330",  // 股票代碼（必要欄位）
  "name": "台積電",       // 公司名稱
  // ... 其他欄位
}
```

**支援的股票代碼欄位名稱：**
- `stock_code`
- `code`
- `股票代碼`
- `symbol`
- `ticker`

## 檔案說明

| 檔案 | 功能 | 重要性 |
|------|------|--------|
| `main.py` | 主程式入口 | ⭐⭐⭐ |
| `mops_scraper.py` | 爬蟲核心邏輯 | ⭐⭐⭐ |
| `db_manager.py` | MongoDB 資料庫管理 | ⭐⭐⭐ |
| `config.py` | 配置管理 | ⭐⭐⭐ |
| `test_connection.py` | 連接測試工具 | ⭐⭐ |
| `test_scraper.py` | 爬蟲測試工具 | ⭐⭐ |
| `requirements.txt` | 套件依賴 | ⭐⭐⭐ |
| `.env.example` | 環境變數範例 | ⭐⭐ |

## 配置說明

### 重要參數（在 .env 中設定）

```env
# MongoDB 配置
MONGODB_URI=mongodb://localhost:27017/     # MongoDB 連接字串
MONGODB_DATABASE=TW_Stock                  # 資料庫名稱
COMPANY_COLLECTION=公司基本資料             # 公司資料表名稱
BALANCE_SHEET_COLLECTION=歷史負債資料       # 輸出資料表名稱

# 爬蟲效能配置
MAX_CONCURRENT_REQUESTS=5    # 並發請求數（1-20）
REQUEST_DELAY=2              # 請求間隔秒數（1-5）
RETRY_TIMES=3                # 失敗重試次數（1-5）
TIMEOUT=30                   # 請求逾時秒數（10-60）
```

### 效能調校建議

#### 保守設定（安全，較慢）
```env
MAX_CONCURRENT_REQUESTS=3
REQUEST_DELAY=3
```
- 成功率：~95%
- 速度：慢
- 風險：低

#### 平衡設定（推薦）
```env
MAX_CONCURRENT_REQUESTS=5
REQUEST_DELAY=2
```
- 成功率：~90%
- 速度：中等
- 風險：低

#### 激進設定（快速，風險高）
```env
MAX_CONCURRENT_REQUESTS=10
REQUEST_DELAY=1
```
- 成功率：~80%
- 速度：快
- 風險：中（可能被封鎖）

## 執行時間預估

基於 **平衡設定**（5 並發，2 秒延遲）：

| 公司數 | 年份範圍 | 總請求數 | 預估時間 |
|--------|----------|----------|----------|
| 100 家 | 5 年 | ~2,000 | 1-2 小時 |
| 500 家 | 10 年 | ~20,000 | 11-13 小時 |
| 1000 家 | 10 年 | ~40,000 | 22-25 小時 |

**計算公式：**
```
總請求數 = 公司數 × 年數 × 4（季度）
預估時間（秒） = 總請求數 × (REQUEST_DELAY + 處理時間)
```

## 使用範例

### 範例 1：爬取所有公司（預設）

```bash
python main.py
```

### 範例 2：只爬取特定公司

編輯 `main.py`，找到這段程式碼：

```python
# 原始碼
stock_codes = db_manager.get_company_stock_codes()

# 修改為
stock_codes = ['2330', '2317', '2454']  # 台積電、鴻海、聯發科
```

### 範例 3：只爬取特定年份範圍

編輯 `main.py`，修改起始年份：

```python
start_year = 110  # 只爬取民國 110 年（2021）之後的資料
```

### 範例 4：測試單一公司

```bash
# 測試台積電（2330）
python test_scraper.py

# 測試多家公司
python test_scraper.py multi
```

## 後台執行（長時間爬取）

### Linux/Mac 使用 nohup

```bash
# 啟動
nohup python main.py > output.log 2>&1 &

# 查看執行狀態
tail -f output.log

# 查看進程
ps aux | grep main.py

# 停止
kill <PID>
```

### Linux/Mac 使用 screen

```bash
# 建立新 session
screen -S mops_scraper

# 執行程式
python main.py

# 離開（不中斷程式）：按 Ctrl+A 然後 D

# 重新連接
screen -r mops_scraper

# 停止
screen -X -S mops_scraper quit
```

### Windows 背景執行

```powershell
# 使用 PowerShell
Start-Process python -ArgumentList "main.py" -WindowStyle Hidden

# 或建立排程工作
```

## 監控與除錯

### 1. 即時監控日誌

```bash
# 查看最新日誌
tail -f scraper_*.log

# 過濾特定內容
tail -f scraper_*.log | grep "成功"
tail -f scraper_*.log | grep "ERROR"
```

### 2. 查詢資料庫進度

```javascript
// 連接 MongoDB
use TW_Stock

// 查看總資料筆數
db.歷史負債資料.count()

// 查看已完成的公司數
db.歷史負債資料.distinct("stock_code").length

// 查看特定公司的進度
db.歷史負債資料.find({stock_code: "2330"}).count()

// 查看最新爬取時間
db.歷史負債資料.find().sort({crawl_time: -1}).limit(1)

// 按公司統計資料筆數
db.歷史負債資料.aggregate([
  {$group: {_id: "$stock_code", count: {$sum: 1}}},
  {$sort: {count: -1}}
])
```

### 3. 檢查錯誤

```bash
# 查看所有錯誤
grep "ERROR" scraper_*.log

# 統計錯誤類型
grep "ERROR" scraper_*.log | sort | uniq -c

# 查看特定公司的錯誤
grep "2330" scraper_*.log | grep "ERROR"
```

## 常見問題

### Q1: MongoDB 連接失敗

**錯誤訊息：**
```
MongoDB 連接失敗: [WinError 10061] 無法連線
```

**解決方法：**
```bash
# 1. 確認 MongoDB 是否執行
mongosh

# 2. 啟動 MongoDB（如果沒執行）
# Windows: 服務管理員啟動 MongoDB
# Mac: brew services start mongodb-community
# Linux: sudo systemctl start mongod

# 3. 使用 Docker 啟動（備選方案）
docker run -d -p 27017:27017 --name mongodb mongo
```

### Q2: 找不到公司基本資料

**錯誤訊息：**
```
未找到任何公司資料，請檢查 MongoDB
```

**解決方法：**

1. 檢查 collection 名稱是否正確：
```javascript
use TW_Stock
show collections
```

2. 檢查資料是否存在：
```javascript
db.公司基本資料.findOne()
```

3. 修改 `.env` 中的 collection 名稱

### Q3: 無法識別股票代碼欄位

**錯誤訊息：**
```
無法識別股票代碼欄位。可用欄位: ['_id', 'company_code', ...]
```

**解決方法：**

查看日誌中顯示的可用欄位，然後修改 `db_manager.py`：

```python
# 在 get_company_stock_codes() 方法中
field_names = ['stock_code', 'code', '股票代碼', 'symbol', 'ticker', 'company_code']
```

將你的欄位名稱加入 `field_names` 清單中。

### Q4: 被 MOPS 伺服器封鎖

**症狀：**
- 大量請求失敗
- 回應狀態碼 403 或 429
- 連續的逾時錯誤

**解決方法：**

1. 降低爬取速度：
```env
MAX_CONCURRENT_REQUESTS=2
REQUEST_DELAY=5
```

2. 暫停一段時間（30-60 分鐘）

3. 更換網路環境或 IP

### Q5: 爬取速度太慢

**解決方法：**

1. 增加並發數：
```env
MAX_CONCURRENT_REQUESTS=10
```

2. 減少延遲（注意風險）：
```env
REQUEST_DELAY=1
```

3. 只爬取需要的年份範圍

### Q6: 程式中斷後如何續爬

**解決方法：**

直接重新執行即可！系統使用 upsert 機制，會自動跳過已存在的資料：

```bash
python main.py
```

系統會：
- 讀取所有公司清單
- 嘗試爬取所有年份和季度
- 自動更新已存在的資料或新增新資料
- 不會產生重複記錄

## 資料驗證

### 檢查資料完整性

```javascript
// 查看每家公司的資料筆數
db.歷史負債資料.aggregate([
  {$group: {
    _id: "$stock_code",
    count: {$sum: 1},
    years: {$addToSet: "$year"},
    seasons: {$addToSet: "$season"}
  }},
  {$sort: {count: -1}}
])

// 檢查是否有缺失的季度
db.歷史負債資料.find({stock_code: "2330"}).sort({year: 1, season: 1})
```

### 匯出資料

```python
# export_data.py
from db_manager import MongoDBManager
import pandas as pd

db = MongoDBManager()
data = list(db.balance_sheet_collection.find({}))

# 轉換為 DataFrame
df = pd.DataFrame(data)

# 匯出為 CSV
df.to_csv('balance_sheet_data.csv', index=False, encoding='utf-8-sig')

# 或匯出為 Excel
df.to_excel('balance_sheet_data.xlsx', index=False)

db.close()
print("資料匯出完成！")
```

## 進階技巧

### 1. 分時段爬取

```python
# 在 main.py 中修改
# 上午爬前 500 家
stock_codes = db_manager.get_company_stock_codes()[:500]

# 下午爬後 500 家
stock_codes = db_manager.get_company_stock_codes()[500:]
```

### 2. 依產業分類爬取

```python
# 從資料庫篩選特定產業
companies = db_manager.company_collection.find({'industry': '半導體業'})
stock_codes = [c['stock_code'] for c in companies]
```

### 3. 只更新最新季度

```python
# 修改 _get_year_season_list 方法
current_year = datetime.now().year - 1911
current_season = (datetime.now().month - 1) // 3 + 1
return [(current_year, current_season)]  # 只爬最新一季
```

## 效能優化檢查清單

- [ ] MongoDB 索引已建立
- [ ] 並發數設定適當（5-10）
- [ ] 請求延遲合理（1-3 秒）
- [ ] 網路連接穩定
- [ ] 足夠的磁碟空間
- [ ] Python 版本 3.8+
- [ ] 依賴套件已安裝

## 技術支援

遇到問題時，請提供以下資訊：

1. 錯誤訊息（日誌檔案內容）
2. 執行環境（作業系統、Python 版本）
3. MongoDB 版本
4. `.env` 配置內容（隱藏敏感資訊）
5. 測試程式的執行結果

## 授權聲明

本系統僅供學習和研究使用，請遵守：

- MOPS 網站使用條款
- 個人資料保護法
- 相關金融法規
- 爬蟲禮儀和道德規範

**請勿：**
- 過度頻繁請求造成伺服器負擔
- 將資料用於商業用途（未經授權）
- 散布或販售爬取的資料
- 規避網站的安全機制

---

**最後更新：2024-12-04**
**版本：1.0.0**
